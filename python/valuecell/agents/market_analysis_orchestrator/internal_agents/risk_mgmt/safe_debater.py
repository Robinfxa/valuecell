"""Conservative Risk Debater - Risk-averse advocate.

Advocates for capital preservation and cautious approach.
"""

from typing import Any, Callable, Dict, Optional

from loguru import logger

SAFE_DEBATER_PROMPT = """ä½œä¸ºä¿å®ˆé£é™©åˆ†æå¸ˆï¼Œä½ çš„èŒè´£æ˜¯å¼ºè°ƒèµ„æœ¬ä¿æŠ¤å’Œé£é™©è§„é¿ã€‚

## äº¤æ˜“å‘˜å†³ç­–
{trader_decision}

## å¯ç”¨ä¿¡æ¯
å¸‚åœºç ”ç©¶æŠ¥å‘Šï¼š{market_report}
æƒ…ç»ªæŠ¥å‘Šï¼š{sentiment_report}
æ–°é—»æŠ¥å‘Šï¼š{news_report}
åŸºæœ¬é¢æŠ¥å‘Šï¼š{fundamentals_report}

## å¯¹è¯å†å²
{risk_history}

## æ¿€è¿›åˆ†æå¸ˆè§‚ç‚¹
{risky_response}

## ä¸­æ€§åˆ†æå¸ˆè§‚ç‚¹
{neutral_response}

## ä½ çš„ä»»åŠ¡
- å¼ºè°ƒæ½œåœ¨é£é™©å’Œä¸‹è¡Œå¯èƒ½
- å»ºè®®è°¨æ…çš„ä»“ä½ç®¡ç†
- è´¨ç–‘è¿‡äºä¹è§‚çš„å‡è®¾
- æå‡ºé£é™©æ§åˆ¶æªæ–½

è¯·ç”¨ä¸­æ–‡ä»¥å¯¹è¯æ–¹å¼è¾“å‡ºè®ºç‚¹ã€‚
"""


def create_safe_debater(llm: Any = None) -> Callable:
    """Create conservative risk debater node.

    Args:
        llm: Language model instance (optional)

    Returns:
        Node function for LangGraph workflow
    """

    def safe_node(state: Dict[str, Any]) -> Dict[str, Any]:
        logger.info("ğŸ›¡ï¸ [ä¿å®ˆé£é™©åˆ†æå¸ˆ] å¼€å§‹è®ºè¯")

        # Get reports
        market_report = state.get("market_report", "")
        sentiment_report = state.get("sentiment_report", "")
        news_report = state.get("news_report", "")
        fundamentals_report = state.get("fundamentals_report", "")
        trader_decision = state.get("trader_investment_plan", "")

        # Get risk debate state
        risk_state = state.get("risk_debate_state") or {}
        risk_history = risk_state.get("history", "")
        safe_history = risk_state.get("safe_history", "")
        risky_response = risk_state.get("current_risky_response", "")
        neutral_response = risk_state.get("current_neutral_response", "")

        prompt = SAFE_DEBATER_PROMPT.format(
            trader_decision=trader_decision or "å¾…è¯„ä¼°",
            market_report=market_report or "æš‚æ— ",
            sentiment_report=sentiment_report or "æš‚æ— ",
            news_report=news_report or "æš‚æ— ",
            fundamentals_report=fundamentals_report or "æš‚æ— ",
            risk_history=risk_history or "æ— å†å²",
            risky_response=risky_response or "æš‚æ— ",
            neutral_response=neutral_response or "æš‚æ— ",
        )

        try:
            if llm is not None:
                response = llm.invoke(prompt)
                argument = response.content if hasattr(response, "content") else str(response)
            else:
                argument = "ä¿å®ˆè§‚ç‚¹: å½“å‰å¸‚åœºä¸ç¡®å®šæ€§è¾ƒé«˜ï¼Œå»ºè®®æ§åˆ¶ä»“ä½ï¼Œè®¾ç½®æ­¢æŸï¼Œä¿æŠ¤æœ¬é‡‘"
        except Exception as e:
            logger.exception(f"âŒ [ä¿å®ˆé£é™©åˆ†æå¸ˆ] ç”Ÿæˆå¤±è´¥: {e}")
            argument = f"ä¿å®ˆåˆ†æå¤±è´¥: {e}"

        full_argument = f"Safe Analyst: {argument}"

        # Update risk debate state
        new_risk_state = {
            "history": risk_history + "\n" + full_argument,
            "risky_history": risk_state.get("risky_history", ""),
            "safe_history": safe_history + "\n" + full_argument,
            "neutral_history": risk_state.get("neutral_history", ""),
            "latest_speaker": "Safe",
            "current_risky_response": risk_state.get("current_risky_response", ""),
            "current_safe_response": full_argument,
            "current_neutral_response": risk_state.get("current_neutral_response", ""),
            "count": risk_state.get("count", 0) + 1,
        }

        logger.info(f"âœ… [ä¿å®ˆé£é™©åˆ†æå¸ˆ] å®Œæˆï¼Œè®ºç‚¹é•¿åº¦: {len(argument)}")

        return {"risk_debate_state": new_risk_state}

    return safe_node
